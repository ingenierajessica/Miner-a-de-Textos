{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MINERÍA DE TEXTOS\n",
    "\n",
    "## Alumna: Jessica Sarahi Méndez Rincón\n",
    "\n",
    "\n",
    "###  Tarea 10\n",
    "### Clase 11 Tarea 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Publicado el 12 abr. (Última modificación: 27 abr.)\n",
    "\n",
    "Tarea asignada\n",
    "\n",
    "Comprobar la similaridad entre 20 pares de palabras tomados de:\n",
    "\n",
    "A validated translation of the original Miller-Charles (Miller and Charles, 1998) and WordSimilarity-353 (Finkelstein et al., 2001) in Spanish, Romanian, and Arabic.\n",
    "\n",
    "1- Calcular la similitud entre cada par de palabras usando los modelos de vectores: word2vec, GloVe, fastTex, elmo, bert.\n",
    "     \n",
    "     ->   Word2Vec (por Google) \n",
    "     \n",
    "    - >   Glove (por Stanford) \n",
    "    \n",
    "     ->   FastText (por Facebook) \n",
    "     \n",
    "\n",
    "\n",
    "2- Calcular la similitud entre cada par de palabras a partir de las medidas dada con WordNet en inglés y en español.\n",
    "\n",
    "3- Evaluar el rendimiento de los diferentes métodos probados usando la medida de correlación de Pearson.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img scr=https://miro.medium.com/max/852/1*5J8YlnfnZlzFobQC9cGk-w.png>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obteniendo información"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nltk\n",
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importacion del archivo que se nos proporciono agregandole cabeceras que no contiene \n",
    "rs_MC30 = pd.read_csv('MC30.csv', delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EN.1</th>\n",
       "      <th>EN.2</th>\n",
       "      <th>RO.1</th>\n",
       "      <th>RO.2</th>\n",
       "      <th>AR.1</th>\n",
       "      <th>AR.2</th>\n",
       "      <th>ES.1</th>\n",
       "      <th>ES.2</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>asylum</td>\n",
       "      <td>madhouse</td>\n",
       "      <td>azil</td>\n",
       "      <td>sanatoriu</td>\n",
       "      <td>ملجأ</td>\n",
       "      <td>مأوى</td>\n",
       "      <td>asilo</td>\n",
       "      <td>manicomio</td>\n",
       "      <td>3.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bird</td>\n",
       "      <td>cock</td>\n",
       "      <td>pasăre</td>\n",
       "      <td>cocoş</td>\n",
       "      <td>طير</td>\n",
       "      <td>ديك</td>\n",
       "      <td>pajaro</td>\n",
       "      <td>gallo</td>\n",
       "      <td>3.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bird</td>\n",
       "      <td>crane</td>\n",
       "      <td>pasăre</td>\n",
       "      <td>cocor</td>\n",
       "      <td>طائر</td>\n",
       "      <td>كركي</td>\n",
       "      <td>pajaro</td>\n",
       "      <td>grulla</td>\n",
       "      <td>2.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>boy</td>\n",
       "      <td>lad</td>\n",
       "      <td>băiat</td>\n",
       "      <td>fecior</td>\n",
       "      <td>ولد</td>\n",
       "      <td>صبي</td>\n",
       "      <td>chico</td>\n",
       "      <td>muchacho</td>\n",
       "      <td>3.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>brother</td>\n",
       "      <td>monk</td>\n",
       "      <td>frate</td>\n",
       "      <td>călugăr</td>\n",
       "      <td>شقيق</td>\n",
       "      <td>راهب</td>\n",
       "      <td>hermano</td>\n",
       "      <td>monje</td>\n",
       "      <td>2.82</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      EN.1      EN.2    RO.1       RO.2  AR.1  AR.2     ES.1       ES.2  score\n",
       "0   asylum  madhouse    azil  sanatoriu  ملجأ  مأوى    asilo  manicomio   3.61\n",
       "1     bird      cock  pasăre      cocoş   طير   ديك   pajaro      gallo   3.05\n",
       "2     bird     crane  pasăre      cocor  طائر  كركي   pajaro     grulla   2.97\n",
       "3      boy       lad   băiat     fecior   ولد   صبي    chico   muchacho   3.76\n",
       "4  brother      monk   frate    călugăr  شقيق  راهب  hermano      monje   2.82"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_MC30.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 9)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_MC30.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importacion del archivo que se nos proporciono agregandole cabeceras que no contiene \n",
    "rs_WS353 = pd.read_csv('WS353.csv', delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EN.1</th>\n",
       "      <th>EN.2</th>\n",
       "      <th>RO.1</th>\n",
       "      <th>RO.2</th>\n",
       "      <th>AR.1</th>\n",
       "      <th>AR.2</th>\n",
       "      <th>ES.1</th>\n",
       "      <th>ES.2</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>admission</td>\n",
       "      <td>ticket</td>\n",
       "      <td>intrare</td>\n",
       "      <td>bilet</td>\n",
       "      <td>إدخال</td>\n",
       "      <td>تذكرة</td>\n",
       "      <td>entrada</td>\n",
       "      <td>boleto</td>\n",
       "      <td>7.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>alcohol</td>\n",
       "      <td>chemistry</td>\n",
       "      <td>alcool</td>\n",
       "      <td>chimie</td>\n",
       "      <td>كحول</td>\n",
       "      <td>كيمياء</td>\n",
       "      <td>alcohol</td>\n",
       "      <td>quimica</td>\n",
       "      <td>5.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aluminum</td>\n",
       "      <td>metal</td>\n",
       "      <td>aluminiu</td>\n",
       "      <td>metal</td>\n",
       "      <td>المونيوم</td>\n",
       "      <td>معدن</td>\n",
       "      <td>aluminio</td>\n",
       "      <td>metal</td>\n",
       "      <td>7.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>announcement</td>\n",
       "      <td>effort</td>\n",
       "      <td>anunţ</td>\n",
       "      <td>efort</td>\n",
       "      <td>تصريح</td>\n",
       "      <td>جهد</td>\n",
       "      <td>anuncio</td>\n",
       "      <td>esfuerzo</td>\n",
       "      <td>2.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>announcement</td>\n",
       "      <td>news</td>\n",
       "      <td>anunţ</td>\n",
       "      <td>ştiri</td>\n",
       "      <td>تصريح</td>\n",
       "      <td>أخبار</td>\n",
       "      <td>anuncio</td>\n",
       "      <td>noticias</td>\n",
       "      <td>7.56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           EN.1       EN.2      RO.1    RO.2      AR.1    AR.2      ES.1  \\\n",
       "0     admission     ticket   intrare   bilet     إدخال   تذكرة   entrada   \n",
       "1       alcohol  chemistry    alcool  chimie      كحول  كيمياء   alcohol   \n",
       "2      aluminum      metal  aluminiu   metal  المونيوم    معدن  aluminio   \n",
       "3  announcement     effort     anunţ   efort     تصريح     جهد   anuncio   \n",
       "4  announcement       news     anunţ   ştiri     تصريح   أخبار   anuncio   \n",
       "\n",
       "       ES.2  score  \n",
       "0    boleto   7.69  \n",
       "1   quimica   5.54  \n",
       "2     metal   7.83  \n",
       "3  esfuerzo   2.75  \n",
       "4  noticias   7.56  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_WS353.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(352, 9)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_WS353.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.- Similaridad de palabras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synsets('palabra')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('chase.v.01')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synsets('dog', pos= wn.VERB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Lemma('dog.n.01.dog'),\n",
       " Lemma('dog.n.01.domestic_dog'),\n",
       " Lemma('dog.n.01.Canis_familiaris')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synset('dog.n.01').lemmas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dog', 'domestic_dog', 'Canis_familiaris']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[str(lemma.name()) for lemma in\n",
    "wn.synset('dog.n.01').lemmas()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "good = wn.synset('good.a.01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dog = wn.synset('dog.n.01')\n",
    "cat = wn.synset('cat.n.01')\n",
    "dog.path_similarity(cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14285714285714285"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hit = wn.synset('hit.v.01')\n",
    "slap = wn.synset('slap.v.01')\n",
    "wn.path_similarity(hit, slap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0281482472922856"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dog.lch_similarity(cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('entity.n.01')\n",
      "Synset('physical_entity.n.01')\n",
      "Synset('abstraction.n.06')\n",
      "Synset('thing.n.12')\n",
      "Synset('object.n.01')\n",
      "Synset('whole.n.02')\n",
      "Synset('congener.n.03')\n",
      "Synset('living_thing.n.01')\n",
      "Synset('organism.n.01')\n",
      "Synset('benthos.n.02')\n"
     ]
    }
   ],
   "source": [
    "for synset in list(wn.all_synsets('n'))[:10]:\n",
    "    print(synset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.- a) Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python program to generate word vectors using Word2Vec \n",
    "  \n",
    "# importing all necessary modules \n",
    "from nltk.tokenize import sent_tokenize, word_tokenize \n",
    "import warnings \n",
    "  \n",
    "warnings.filterwarnings(action = 'ignore') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim \n",
    "from gensim.models import Word2Vec "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for col in rs_MC30[['EN.1', 'EN.2']] :\n",
    "#    print(rs_MC30[col])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create CBOW model \n",
    "model1 = gensim.models.Word2Vec(rs_MC30[['ES.1', 'ES.2']], min_count = 1,size = 100, window = 5) \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model1.similarity('asilo', 'manicomio')\n",
    "#model.most_similar(positive=['woman', 'king'],negative=['man'], topn=1)\n",
    "#model.doesnt_match(\"breakfast cereal dinner lunch\";.split())\n",
    "#model['computer'] # devuelve el vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-87ed2ec94738>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mWord2Vec\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mWord2Vec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0myour\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msimilarity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'france'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'spain'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'path' is not defined"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "model = Word2Vec.load(path/to/your/model)\n",
    "model.similarity('france', 'spain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "asylum-madhouse =>3.61\n",
      "bird-cock =>3.05\n",
      "bird-crane =>2.97\n",
      "boy-lad =>3.76\n",
      "brother-monk =>2.82\n",
      "car-automobile =>3.92\n",
      "cemetery-woodland =>0.95\n",
      "chord-smile =>0.13\n",
      "coast-forest =>0.42\n",
      "coast-hill =>0.87\n",
      "coast-shore =>3.7\n",
      "crane-implement =>1.68\n",
      "food-fruit =>3.08\n",
      "food-rooster =>0.89\n",
      "forest-graveyard =>0.84\n",
      "furnace-stove =>3.11\n",
      "gem-jewel =>3.84\n",
      "glass-magician =>0.11\n",
      "journey-car =>1.16\n",
      "journey-voyage =>3.84\n",
      "lad-brother =>1.66\n",
      "lad-wizard =>0.42\n",
      "magician-wizard =>3.5\n",
      "midday-noon =>3.42\n",
      "monk-oracle =>1.1\n",
      "monk-slave =>0.55\n",
      "noon-string =>0.08\n",
      "rooster-voyage =>0.08\n",
      "shore-woodland =>0.63\n",
      "tool-implement =>2.95\n"
     ]
    }
   ],
   "source": [
    "for indice_fila, fila in rs_MC30[['EN.1', 'EN.2','score']].iterrows():\n",
    "    #print(indice_fila)\n",
    "    \n",
    "    #similaridad= model1.similarity(fila[0], fila[1]) \n",
    "    print(fila[0]+'-'+fila[1]+' =>'+str(fila[2]))\n",
    "    #print(model1.similarity(fila[0], fila[1]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Se usa word2vec con el corpus abc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package abc to\n",
      "[nltk_data]     C:\\Users\\Jess\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package abc is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('abc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('law', 0.9364699721336365), ('policy', 0.9274913668632507), ('agriculture', 0.9270479679107666), ('general', 0.9230339527130127), ('media', 0.9216471314430237), ('practice', 0.9189646244049072), ('discussion', 0.9148513078689575), ('board', 0.9069294929504395), ('heritage', 0.9064595699310303), ('Cooper', 0.9060097336769104)]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import gensim\n",
    "from nltk.corpus import abc\n",
    "\n",
    "model= gensim.models.Word2Vec(abc.sents())\n",
    "X= list(model.wv.vocab)\n",
    "data=model.most_similar('science')\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6667487"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.similarity(\"sun\", \"star\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['PM', 'denies', 'knowledge', 'of', 'AWB', 'kickbacks', 'The', 'Prime', 'Minister', 'has', 'denied', 'he', 'knew', 'AWB', 'was', 'paying', 'kickbacks', 'to', 'Iraq', 'despite', 'writing', 'to', 'the', 'wheat', 'exporter', 'asking', 'to', 'be', 'kept', 'fully', 'informed', 'on', 'Iraq', 'wheat', 'sales', '.'], ['Letters', 'from', 'John', 'Howard', 'and', 'Deputy', 'Prime', 'Minister', 'Mark', 'Vaile', 'to', 'AWB', 'have', 'been', 'released', 'by', 'the', 'Cole', 'inquiry', 'into', 'the', 'oil', 'for', 'food', 'program', '.'], ...]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abc.sents()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Se usa word2vec con el corpus text8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para resolcer la tarea se consulta la siguiente URL donde me percate que el corpus es más extenso y por consiguiente contiene una cantidad mayor de palbras en las que se encuentran los scores humanos.\n",
    "\n",
    "URL: https://radimrehurek.com/gensim/auto_examples/tutorials/run_annoy.html\n",
    "\n",
    "URL2: https://radimrehurek.com/gensim/auto_examples/tutorials/run_word2vec.html#sphx-glr-auto-examples-tutorials-run-word2vec-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Jess/gensim-data\\\\text8\\\\text8.gz'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gensim.downloader as api\n",
    "text8_path = api.load('text8', return_path=True)\n",
    "text8_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec(vocab=10363, size=100, alpha=0.025)\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "from gensim.models.word2vec import Text8Corpus\n",
    "\n",
    "# Usando parámetros para Word2Vec\n",
    "params = {\n",
    "    'alpha': 0.05,\n",
    "    'size': 100,\n",
    "    'window': 5,\n",
    "    'iter': 5,\n",
    "    'min_count': 5,\n",
    "    'sample': 1e-4,\n",
    "    'sg': 1,\n",
    "    'hs': 0,\n",
    "    'negative': 5\n",
    "}\n",
    "model_WV_Txt8 = Word2Vec(Text8Corpus(text8_path), **params)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6667487"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.similarity(\"sun\", \"star\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38868535"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_WV_Txt8.similarity(\"bird\", \"cock\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "asylum-madhouse=> Score Human:3.61  Score Word2Vec: **0.15822995**\n",
      "bird-cock=> Score Human:3.05  Score Word2Vec: **0.38868535**\n",
      "bird-crane=> Score Human:2.97  Score Word2Vec: **0.53265774**\n",
      "boy-lad=> Score Human:3.76  Score Word2Vec: **0.34601894**\n",
      "brother-monk=> Score Human:2.82  Score Word2Vec: **0.3273852**\n",
      "car-automobile=> Score Human:3.92  Score Word2Vec: **0.71417606**\n",
      "cemetery-woodland=> Score Human:0.95  Score Word2Vec: **0.43377602**\n",
      "chord-smile=> Score Human:0.13  Score Word2Vec: **0.23664013**\n",
      "coast-forest=> Score Human:0.42  Score Word2Vec: **0.40752247**\n",
      "coast-hill=> Score Human:0.87  Score Word2Vec: **0.3193954**\n",
      "coast-shore=> Score Human:3.7  Score Word2Vec: **0.6800754**\n",
      "crane-implement=> Score Human:1.68  Score Word2Vec: **0.018257432**\n",
      "food-fruit=> Score Human:3.08  Score Word2Vec: **0.57621795**\n",
      "food-rooster=> Score Human:0.89  Score Word2Vec: **0.22158821**\n",
      "forest-graveyard=> Score Human:0.84  Score Word2Vec: **0.44139162**\n",
      "furnace-stove=> Score Human:3.11  Score Word2Vec: **0.50341856**\n",
      "gem-jewel=> Score Human:3.84  Score Word2Vec: **0.3430578**\n",
      "glass-magician=> Score Human:0.11  Score Word2Vec: **0.17801093**\n",
      "journey-car=> Score Human:1.16  Score Word2Vec: **0.31998783**\n",
      "journey-voyage=> Score Human:3.84  Score Word2Vec: **0.61241126**\n",
      "lad-brother=> Score Human:1.66  Score Word2Vec: **0.46189374**\n",
      "lad-wizard=> Score Human:0.42  Score Word2Vec: **0.3738201**\n",
      "magician-wizard=> Score Human:3.5  Score Word2Vec: **0.44740543**\n",
      "midday-noon=> Score Human:3.42  Score Word2Vec: **0.6124944**\n",
      "monk-oracle=> Score Human:1.1  Score Word2Vec: **0.18057738**\n",
      "monk-slave=> Score Human:0.55  Score Word2Vec: **0.25990176**\n",
      "noon-string=> Score Human:0.08  Score Word2Vec: **0.12189391**\n",
      "rooster-voyage=> Score Human:0.08  Score Word2Vec: **0.2751965**\n",
      "shore-woodland=> Score Human:0.63  Score Word2Vec: **0.34170792**\n",
      "tool-implement=> Score Human:2.95  Score Word2Vec: **0.46172363**\n"
     ]
    }
   ],
   "source": [
    "for indice_fila, fila in rs_MC30[['EN.1', 'EN.2','score']].iterrows():\n",
    "    \n",
    "    similaridad= model_WV_Txt8.similarity(fila[0], fila[1]) \n",
    "    print(fila[0]+'-'+fila[1]+'=> Score Human:'+str(fila[2])+'  Score Word2Vec: **'+str(similaridad)+'**')\n",
    "    #print(model1.similarity(fila[0], fila[1]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B)GLOVE Vectores globales para la representación de palabras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400000, 100)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "glove_input_file = 'glove.6B.100d.txt'\n",
    "word2vec_output_file = 'glove.6B.100d.txt.word2vec'\n",
    "glove2word2vec(glove_input_file, word2vec_output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('queen', 0.7698541283607483)]\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "# load the Stanford GloVe model\n",
    "filename = 'glove.6B.100d.txt.word2vec'\n",
    "model = KeyedVectors.load_word2vec_format(filename, binary=False)\n",
    "# calculate: (king - man) + woman = ?\n",
    "result = model.most_similar(positive=['woman', 'king'], negative=['man'], topn=1)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38970053"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.similarity('tool', 'implement') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('asylum-madhouse=> Score Human:3.61  Score Word2Vec: 0.15822995   Score '\n",
      " 'Glove: -0.104345016')\n",
      "('bird-cock=> Score Human:3.05  Score Word2Vec: 0.38868535   Score Glove: '\n",
      " '0.27531016')\n",
      "('bird-crane=> Score Human:2.97  Score Word2Vec: 0.53265774   Score Glove: '\n",
      " '0.3371934')\n",
      "('boy-lad=> Score Human:3.76  Score Word2Vec: 0.34601894   Score Glove: '\n",
      " '0.39526767')\n",
      "('brother-monk=> Score Human:2.82  Score Word2Vec: 0.3273852   Score Glove: '\n",
      " '0.42725784')\n",
      "('car-automobile=> Score Human:3.92  Score Word2Vec: 0.71417606   Score Glove: '\n",
      " '0.68319416')\n",
      "('cemetery-woodland=> Score Human:0.95  Score Word2Vec: 0.43377602   Score '\n",
      " 'Glove: 0.4753443')\n",
      "('chord-smile=> Score Human:0.13  Score Word2Vec: 0.23664013   Score Glove: '\n",
      " '0.20381096')\n",
      "('coast-forest=> Score Human:0.42  Score Word2Vec: 0.40752247   Score Glove: '\n",
      " '0.41092995')\n",
      "('coast-hill=> Score Human:0.87  Score Word2Vec: 0.3193954   Score Glove: '\n",
      " '0.38247383')\n",
      "('coast-shore=> Score Human:3.7  Score Word2Vec: 0.6800754   Score Glove: '\n",
      " '0.70002717')\n",
      "('crane-implement=> Score Human:1.68  Score Word2Vec: 0.018257432   Score '\n",
      " 'Glove: 0.024721691')\n",
      "('food-fruit=> Score Human:3.08  Score Word2Vec: 0.57621795   Score Glove: '\n",
      " '0.57356036')\n",
      "('food-rooster=> Score Human:0.89  Score Word2Vec: 0.22158821   Score Glove: '\n",
      " '-0.006615811')\n",
      "('forest-graveyard=> Score Human:0.84  Score Word2Vec: 0.44139162   Score '\n",
      " 'Glove: 0.23617889')\n",
      "('furnace-stove=> Score Human:3.11  Score Word2Vec: 0.50341856   Score Glove: '\n",
      " '0.63263935')\n",
      "('gem-jewel=> Score Human:3.84  Score Word2Vec: 0.3430578   Score Glove: '\n",
      " '0.64154494')\n",
      "('glass-magician=> Score Human:0.11  Score Word2Vec: 0.17801093   Score Glove: '\n",
      " '0.0922051')\n",
      "('journey-car=> Score Human:1.16  Score Word2Vec: 0.31998783   Score Glove: '\n",
      " '0.34866184')\n",
      "('journey-voyage=> Score Human:3.84  Score Word2Vec: 0.61241126   Score Glove: '\n",
      " '0.76829946')\n",
      "('lad-brother=> Score Human:1.66  Score Word2Vec: 0.46189374   Score Glove: '\n",
      " '0.22992502')\n",
      "('lad-wizard=> Score Human:0.42  Score Word2Vec: 0.3738201   Score Glove: '\n",
      " '0.33802786')\n",
      "('magician-wizard=> Score Human:3.5  Score Word2Vec: 0.44740543   Score Glove: '\n",
      " '0.66182053')\n",
      "('midday-noon=> Score Human:3.42  Score Word2Vec: 0.6124944   Score Glove: '\n",
      " '0.78533125')\n",
      "('monk-oracle=> Score Human:1.1  Score Word2Vec: 0.18057738   Score Glove: '\n",
      " '0.059876')\n",
      "('monk-slave=> Score Human:0.55  Score Word2Vec: 0.25990176   Score Glove: '\n",
      " '0.22086458')\n",
      "('noon-string=> Score Human:0.08  Score Word2Vec: 0.12189391   Score Glove: '\n",
      " '0.03757568')\n",
      "('rooster-voyage=> Score Human:0.08  Score Word2Vec: 0.2751965   Score Glove: '\n",
      " '0.060487404')\n",
      "('shore-woodland=> Score Human:0.63  Score Word2Vec: 0.34170792   Score Glove: '\n",
      " '0.22715843')\n",
      "('tool-implement=> Score Human:2.95  Score Word2Vec: 0.46172363   Score Glove: '\n",
      " '0.38970053')\n"
     ]
    }
   ],
   "source": [
    "for indice_fila, fila in rs_MC30[['EN.1', 'EN.2','score']].iterrows():\n",
    "    \n",
    "    similaridad_glove= model.similarity(fila[0], fila[1]) \n",
    "    similaridad= model_WV_Txt8.similarity(fila[0], fila[1]) \n",
    "    print(fila[0]+'-'+fila[1]+'=> Score Human:'+str(fila[2])+'  Score Word2Vec: '+str(similaridad)+' '+'  Score Glove: '+str(similaridad_glove))\n",
    "    #print(model1.similarity(fila[0], fila[1]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C)FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import FastText\n",
    "# FIXME: why does Sphinx dislike this import?\n",
    "from gensim.test.utils import common_texts  # some example sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['human', 'interface', 'computer']\n"
     ]
    }
   ],
   "source": [
    " print(common_texts[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "print(len(common_texts))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_FT = FastText(size=4, window=3, min_count=1)  # instantiate\n",
    "model_FT.build_vocab(sentences=common_texts)\n",
    "model_FT.train(sentences=common_texts, total_examples=len(common_texts), epochs=10)  # train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2_FT = FastText(size=4, window=3, min_count=1, sentences=common_texts, iter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.allclose(model_FT.wv['computer'], model2_FT.wv['computer'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59890"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.test.utils import datapath\n",
    "\n",
    "corpus_file = datapath('lee_background.cor')  # absolute path to corpus\n",
    "model3_FT = FastText(size=4, window=3, min_count=1)\n",
    "model3_FT.build_vocab(corpus_file=corpus_file)  # scan over corpus to build the vocabulary\n",
    "\n",
    "total_words = model3_FT.corpus_total_words  # number of words in the corpus\n",
    "model3_FT.train(corpus_file=corpus_file, total_words=total_words, epochs=5)\n",
    "total_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.utils import tokenize\n",
    "from gensim import utils\n",
    "\n",
    "\n",
    "class MyIter(object):\n",
    "    def __iter__(self):\n",
    "        path = datapath('crime-and-punishment.txt')\n",
    "        with utils.open(path, 'r', encoding='utf-8') as fin:\n",
    "            for line in fin:\n",
    "                yield list(tokenize(line))\n",
    "\n",
    "\n",
    "model4_FT = FastText(size=4, window=3, min_count=1)\n",
    "model4_FT.build_vocab(sentences=MyIter())\n",
    "total_examples = model4_FT.corpus_count\n",
    "model4_FT.train(sentences=MyIter(), total_examples=total_examples, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import get_tmpfile\n",
    "fname = get_tmpfile(\"fasttext.model\")\n",
    "model_FT.save(fname)\n",
    "model_FT = FastText.load(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " import numpy as np\n",
    "\n",
    "'computation' in model_FT.wv.vocab  # New word, currently out of vocab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_vector = np.copy(model_FT.wv['computation'])  # Grab the existing vector\n",
    "new_sentences = [\n",
    "     ['computer', 'aided', 'design'],\n",
    "     ['computer', 'science'],\n",
    "     ['computational', 'complexity'],\n",
    "     ['military', 'supercomputer'],\n",
    "     ['central', 'processing', 'unit'],\n",
    "     ['onboard', 'car', 'computer'],\n",
    "]\n",
    "\n",
    "model_FT.build_vocab(new_sentences, update=True)  # Update the vocabulary\n",
    "model_FT.train(new_sentences, total_examples=len(new_sentences), epochs=model_FT.epochs)\n",
    "\n",
    "new_vector = model_FT.wv['computation']\n",
    "np.allclose(old_vector, new_vector, atol=1e-4)  # Vector has changed, model has learnt something\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'computation' in model_FT.wv.vocab  # Word is still out of vocab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.80814165"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_score = model_FT.wv.similarity('computer', 'human')\n",
    "sim_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14405861"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_score = model_FT.wv.similarity('bird', 'cock')\n",
    "sim_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('asylum-madhouse=> Score Human:3.61  Score Word2Vec: 0.15822995   Score '\n",
      " 'Glove: -0.104345016   Score FastText: 0.045429353')\n",
      "('bird-cock=> Score Human:3.05  Score Word2Vec: 0.38868535   Score Glove: '\n",
      " '0.27531016   Score FastText: 0.14405861')\n",
      "('bird-crane=> Score Human:2.97  Score Word2Vec: 0.53265774   Score Glove: '\n",
      " '0.3371934   Score FastText: -0.06469475')\n",
      "('boy-lad=> Score Human:3.76  Score Word2Vec: 0.34601894   Score Glove: '\n",
      " '0.39526767   Score FastText: 0.49039865')\n",
      "('brother-monk=> Score Human:2.82  Score Word2Vec: 0.3273852   Score Glove: '\n",
      " '0.42725784   Score FastText: 0.5929469')\n",
      "('car-automobile=> Score Human:3.92  Score Word2Vec: 0.71417606   Score Glove: '\n",
      " '0.68319416   Score FastText: 0.704469')\n",
      "('cemetery-woodland=> Score Human:0.95  Score Word2Vec: 0.43377602   Score '\n",
      " 'Glove: 0.4753443   Score FastText: 0.4557993')\n",
      "('chord-smile=> Score Human:0.13  Score Word2Vec: 0.23664013   Score Glove: '\n",
      " '0.20381096   Score FastText: 0.051004834')\n",
      "('coast-forest=> Score Human:0.42  Score Word2Vec: 0.40752247   Score Glove: '\n",
      " '0.41092995   Score FastText: 0.5416403')\n",
      "('coast-hill=> Score Human:0.87  Score Word2Vec: 0.3193954   Score Glove: '\n",
      " '0.38247383   Score FastText: 0.6178929')\n",
      "('coast-shore=> Score Human:3.7  Score Word2Vec: 0.6800754   Score Glove: '\n",
      " '0.70002717   Score FastText: -0.6600671')\n",
      "('crane-implement=> Score Human:1.68  Score Word2Vec: 0.018257432   Score '\n",
      " 'Glove: 0.024721691   Score FastText: -0.05647291')\n",
      "('food-fruit=> Score Human:3.08  Score Word2Vec: 0.57621795   Score Glove: '\n",
      " '0.57356036   Score FastText: 0.46338362')\n",
      "('food-rooster=> Score Human:0.89  Score Word2Vec: 0.22158821   Score Glove: '\n",
      " '-0.006615811   Score FastText: 0.60238814')\n",
      "('forest-graveyard=> Score Human:0.84  Score Word2Vec: 0.44139162   Score '\n",
      " 'Glove: 0.23617889   Score FastText: -0.63862735')\n",
      "('furnace-stove=> Score Human:3.11  Score Word2Vec: 0.50341856   Score Glove: '\n",
      " '0.63263935   Score FastText: -0.1767385')\n",
      "('gem-jewel=> Score Human:3.84  Score Word2Vec: 0.3430578   Score Glove: '\n",
      " '0.64154494   Score FastText: 0.86843747')\n",
      "('glass-magician=> Score Human:0.11  Score Word2Vec: 0.17801093   Score Glove: '\n",
      " '0.0922051   Score FastText: -0.4155625')\n",
      "('journey-car=> Score Human:1.16  Score Word2Vec: 0.31998783   Score Glove: '\n",
      " '0.34866184   Score FastText: 0.031962916')\n",
      "('journey-voyage=> Score Human:3.84  Score Word2Vec: 0.61241126   Score Glove: '\n",
      " '0.76829946   Score FastText: 0.17442876')\n",
      "('lad-brother=> Score Human:1.66  Score Word2Vec: 0.46189374   Score Glove: '\n",
      " '0.22992502   Score FastText: 0.38255668')\n",
      "('lad-wizard=> Score Human:0.42  Score Word2Vec: 0.3738201   Score Glove: '\n",
      " '0.33802786   Score FastText: -0.44163907')\n",
      "('magician-wizard=> Score Human:3.5  Score Word2Vec: 0.44740543   Score Glove: '\n",
      " '0.66182053   Score FastText: -0.5041243')\n",
      "('midday-noon=> Score Human:3.42  Score Word2Vec: 0.6124944   Score Glove: '\n",
      " '0.78533125   Score FastText: -0.13438638')\n",
      "('monk-oracle=> Score Human:1.1  Score Word2Vec: 0.18057738   Score Glove: '\n",
      " '0.059876   Score FastText: -0.17535195')\n",
      "('monk-slave=> Score Human:0.55  Score Word2Vec: 0.25990176   Score Glove: '\n",
      " '0.22086458   Score FastText: -0.81312793')\n",
      "('noon-string=> Score Human:0.08  Score Word2Vec: 0.12189391   Score Glove: '\n",
      " '0.03757568   Score FastText: 0.1617067')\n",
      "('rooster-voyage=> Score Human:0.08  Score Word2Vec: 0.2751965   Score Glove: '\n",
      " '0.060487404   Score FastText: -0.39457864')\n",
      "('shore-woodland=> Score Human:0.63  Score Word2Vec: 0.34170792   Score Glove: '\n",
      " '0.22715843   Score FastText: 0.6033237')\n",
      "('tool-implement=> Score Human:2.95  Score Word2Vec: 0.46172363   Score Glove: '\n",
      " '0.38970053   Score FastText: -0.28254583')\n"
     ]
    }
   ],
   "source": [
    "for indice_fila, fila in rs_MC30[['EN.1', 'EN.2','score']].iterrows():\n",
    "    \n",
    "    similaridad_glove= model.similarity(fila[0], fila[1]) \n",
    "    similaridad= model_WV_Txt8.similarity(fila[0], fila[1]) \n",
    "    sim_score = model_FT.wv.similarity(fila[0], fila[1]) \n",
    "    print(fila[0]+'-'+fila[1]+'=> Score Human:'+str(fila[2])+'  Score Word2Vec: '+str(similaridad)+' '+'  Score Glove: '+str(similaridad_glove)+' '+'  Score FastText: '+str(sim_score))\n",
    "    #print(model1.similarity(fila[0], fila[1]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# D)ELMO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=http://jalammar.github.io/images/transformer-ber-ulmfit-elmo.png>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "import tensorflow_hub as hub\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Exporting/importing meta graphs is not supported when eager execution is enabled. No graph exists when eager execution is enabled.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-89-ab7ad1f37538>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0melmo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhub\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"https://tfhub.dev/google/elmo/2\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0melmo_vectors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jess\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_hub\\module.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, spec, trainable, name, tags)\u001b[0m\n\u001b[0;32m    174\u001b[0m           \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m           \u001b[0mtrainable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_trainable\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 176\u001b[1;33m           tags=self._tags)\n\u001b[0m\u001b[0;32m    177\u001b[0m       \u001b[1;31m# pylint: enable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jess\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_hub\\native_module.py\u001b[0m in \u001b[0;36m_create_impl\u001b[1;34m(self, name, trainable, tags)\u001b[0m\n\u001b[0;32m    384\u001b[0m         \u001b[0mtrainable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    385\u001b[0m         \u001b[0mcheckpoint_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_checkpoint_variables_path\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 386\u001b[1;33m         name=name)\n\u001b[0m\u001b[0;32m    387\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    388\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_export\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvariables_saver\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jess\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_hub\\native_module.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, spec, meta_graph, trainable, checkpoint_path, name)\u001b[0m\n\u001b[0;32m    443\u001b[0m     \u001b[1;31m# TPU training code.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    444\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mscope_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 445\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    446\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_init_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jess\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_hub\\native_module.py\u001b[0m in \u001b[0;36m_init_state\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    446\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_init_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 448\u001b[1;33m     \u001b[0mvariable_tensor_map\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state_map\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_state_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    449\u001b[0m     self._variable_map = recover_partitioned_variable_map(\n\u001b[0;32m    450\u001b[0m         get_node_map_from_tensor_map(variable_tensor_map))\n",
      "\u001b[1;32mc:\\users\\jess\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_hub\\native_module.py\u001b[0m in \u001b[0;36m_create_state_graph\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    503\u001b[0m         \u001b[0mmeta_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    504\u001b[0m         \u001b[0minput_map\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 505\u001b[1;33m         import_scope=relative_scope_name)\n\u001b[0m\u001b[0;32m    506\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    507\u001b[0m     \u001b[1;31m# Build a list from the variable name in the module definition to the actual\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jess\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_core\\python\\training\\saver.py\u001b[0m in \u001b[0;36mimport_meta_graph\u001b[1;34m(meta_graph_or_file, clear_devices, import_scope, **kwargs)\u001b[0m\n\u001b[0;32m   1451\u001b[0m   return _import_meta_graph_with_return_elements(meta_graph_or_file,\n\u001b[0;32m   1452\u001b[0m                                                  \u001b[0mclear_devices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimport_scope\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1453\u001b[1;33m                                                  **kwargs)[0]\n\u001b[0m\u001b[0;32m   1454\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jess\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_core\\python\\training\\saver.py\u001b[0m in \u001b[0;36m_import_meta_graph_with_return_elements\u001b[1;34m(meta_graph_or_file, clear_devices, import_scope, return_elements, **kwargs)\u001b[0m\n\u001b[0;32m   1461\u001b[0m   \u001b[1;34m\"\"\"Import MetaGraph, and return both a saver and returned elements.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1462\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1463\u001b[1;33m     raise RuntimeError(\"Exporting/importing meta graphs is not supported when \"\n\u001b[0m\u001b[0;32m   1464\u001b[0m                        \u001b[1;34m\"eager execution is enabled. No graph exists when eager \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1465\u001b[0m                        \"execution is enabled.\")\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Exporting/importing meta graphs is not supported when eager execution is enabled. No graph exists when eager execution is enabled."
     ]
    }
   ],
   "source": [
    " \n",
    "elmo = hub.Module(\"https://tfhub.dev/google/elmo/2\", trainable=True)\n",
    " \n",
    " \n",
    "def elmo_vectors(x):\n",
    "   \n",
    "  embeddings=elmo(x, signature=\"default\", as_dict=True)[\"elmo\"]\n",
    "  \n",
    "  with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.tables_initializer())\n",
    "    # return average of ELMo features\n",
    "    return sess.run(tf.reduce_mean(embeddings,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# D) BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=http://jalammar.github.io/images/bert-transfer-learning.png>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorch-pretrained-bert\n",
      "  Downloading pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123 kB)\n",
      "Collecting regex\n",
      "  Downloading regex-2020.4.4-cp37-cp37m-win_amd64.whl (271 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\jess\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from pytorch-pretrained-bert) (1.18.2)\n",
      "Requirement already satisfied: boto3 in c:\\users\\jess\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from pytorch-pretrained-bert) (1.12.31)\n",
      "Collecting tqdm\n",
      "  Downloading tqdm-4.46.0-py2.py3-none-any.whl (63 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\jess\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from pytorch-pretrained-bert) (2.23.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement torch>=0.4.1 (from pytorch-pretrained-bert) (from versions: 0.1.2, 0.1.2.post1, 0.1.2.post2)\n",
      "ERROR: No matching distribution found for torch>=0.4.1 (from pytorch-pretrained-bert)\n",
      "WARNING: You are using pip version 20.0.2; however, version 20.1 is available.\n",
      "You should consider upgrading via the 'c:\\users\\jess\\appdata\\local\\programs\\python\\python37\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install pytorch-pretrained-bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow-gpu\n",
      "  Downloading tensorflow_gpu-2.1.0-cp37-cp37m-win_amd64.whl (356.5 MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an EnvironmentError: [Errno 28] No space left on device\n",
      "\n",
      "WARNING: You are using pip version 20.0.2; however, version 20.1 is available.\n",
      "You should consider upgrading via the 'c:\\users\\jess\\appdata\\local\\programs\\python\\python37\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bert-serving-server\n",
      "  Downloading bert_serving_server-1.10.0-py3-none-any.whl (61 kB)\n",
      "Collecting bert-serving-client\n",
      "  Downloading bert_serving_client-1.10.0-py2.py3-none-any.whl (28 kB)\n",
      "Requirement already satisfied, skipping upgrade: six in c:\\users\\jess\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from bert-serving-server) (1.14.0)\n",
      "Requirement already satisfied, skipping upgrade: termcolor>=1.1 in c:\\users\\jess\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from bert-serving-server) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: pyzmq>=17.1.0 in c:\\users\\jess\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from bert-serving-server) (19.0.0)\n",
      "Collecting GPUtil>=1.3.0\n",
      "  Downloading GPUtil-1.4.0.tar.gz (5.5 kB)\n",
      "Requirement already satisfied, skipping upgrade: numpy in c:\\users\\jess\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from bert-serving-server) (1.18.2)\n",
      "Building wheels for collected packages: GPUtil\n",
      "  Building wheel for GPUtil (setup.py): started\n",
      "  Building wheel for GPUtil (setup.py): finished with status 'done'\n",
      "  Created wheel for GPUtil: filename=GPUtil-1.4.0-py3-none-any.whl size=7414 sha256=25108ac20a897a1a9b88fc9cd4e056ee3a10d63f87086f5d604f9c71efdc943d\n",
      "  Stored in directory: c:\\users\\jess\\appdata\\local\\pip\\cache\\wheels\\6e\\f8\\83\\534c52482d6da64622ddbf72cd93c35d2ef2881b78fd08ff0c\n",
      "Successfully built GPUtil\n",
      "Installing collected packages: GPUtil, bert-serving-server, bert-serving-client\n",
      "Successfully installed GPUtil-1.4.0 bert-serving-client-1.10.0 bert-serving-server-1.10.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.0.2; however, version 20.1 is available.\n",
      "You should consider upgrading via the 'c:\\users\\jess\\appdata\\local\\programs\\python\\python37\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install -U bert-serving-server bert-serving-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "can't assign to operator (<ipython-input-94-234e5bc05f59>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-94-234e5bc05f59>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    bert-serving-start -model_dir /path_to_the_model/ -num_workers=1\u001b[0m\n\u001b[1;37m                                                                    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m can't assign to operator\n"
     ]
    }
   ],
   "source": [
    "bert-serving-start\n",
    "-model_dir /path_to_the_model/ \n",
    "-num_workers=1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
